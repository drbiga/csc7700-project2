# ---------------------------------------------
# This file was mostly generated by ChatGPT and altered to fit our purposes.
from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, col, desc
from graphframes import GraphFrame
import graphframes


def compute_and_save_pagerank(file_path, output_parquet_path):
    spark = (
        SparkSession.builder.appName("PageRankComputation")
        .config("spark.driver.memory", "4g")
        .config("spark.sql.caseSensitive", "true")
        # .config("spark.jars", "jars/graphframes-0.8.3-spark3.4-s_2.12.jar")
        .config("spark.jars.packages", "graphframes:graphframes:0.8.3-spark3.4-s_2.12")
        .getOrCreate()
    )

    df = spark.read.option("multiLine", True).json(file_path)

    # Explode references to get edges
    edges = df.select(
        col("id").cast("double").alias("src"),
        explode("references").alias("dst"),
    ).select(col("src"), col("dst").cast("double"))
    vertices = df.select(col("id").cast("double").alias("id")).distinct()

    g = GraphFrame(vertices, edges)
    results = g.pageRank(resetProbability=0.15, maxIter=1000)

    # Save PageRank scores as Parquet
    results.vertices.write.mode("overwrite").parquet(output_parquet_path)
    print(f"Saved PageRank results as Parquet to {output_parquet_path}")

    spark.stop()


def get_top_n_ranked_nodes(pagerank_parquet_path, n):
    spark = (
        SparkSession.builder.config("spark.sql.caseSensitive", "true").appName(
            "TopPageRankRetriever"
        )
        # .config("spark.jars.packages", "graphframes:graphframes:0.8.2-spark3.1-s_2.12")
        .getOrCreate()
    )

    pr_df = spark.read.parquet(pagerank_parquet_path)

    top_n = (
        pr_df.orderBy(desc("pagerank"))
        .limit(n)
        .select("id", "pagerank")
        .rdd.map(lambda row: (row["id"], row["pagerank"]))
        .collect()
    )

    spark.stop()
    return top_n
